{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Internet Analysis.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMBXpzZgVYVl1Yt5tXDN9eW"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8uPP0lXsVW1r"
      },
      "source": [
        "## Import Necessary Packages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pdOOVeogVDJ2"
      },
      "source": [
        "import pandas as pd\n",
        "import urllib.request"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n2hGakvfVxcm"
      },
      "source": [
        "## Data Cleaning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pZ3SxQUkJBBe"
      },
      "source": [
        "week_days=set(['Mon','Tue','Wed','Thu','Fri','Sat','Sun'])\n",
        "clean_data={}\n",
        "index=-1"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AXcYg3Za_1v1"
      },
      "source": [
        "# Parse log file\n",
        "log_file=urllib.request.urlopen('https://raw.githubusercontent.com/kaazima/Internet-Analysis-Project/master/statistics.log')\n",
        "for line in log_file:\n",
        "  unclean_data=line.decode(\"utf-8\")\n",
        "  if unclean_data[:3] in week_days:\n",
        "    index+=1\n",
        "    clean_data[index]={}\n",
        "    clean_data[index]['Day']=unclean_data[:3]\n",
        "    clean_data[index]['Hour']=int(unclean_data.split()[3].split(':')[0])\n",
        "  else:\n",
        "    unclean_data=unclean_data.split(':')\n",
        "    prop=unclean_data[0].strip()\n",
        "    remain=unclean_data[1].strip()\n",
        "    if prop=='Server':\n",
        "      clean_data[index][prop]=remain.split('(')[0].strip()\n",
        "    elif prop=='Latency' and remain!='FAILED':\n",
        "      remain=remain.split('(')\n",
        "      clean_data[index][prop]=float(remain[0].strip().split()[0])\n",
        "      clean_data[index]['Jitter']=float(remain[1].split()[0])\n",
        "    elif (prop=='Download' or prop=='Upload') and remain!='FAILED':\n",
        "      clean_data[index][prop]=float(remain.split()[0])\n",
        "    elif prop=='Packet Loss' and remain!='Not available.':\n",
        "      clean_data[index][prop]=float(remain.split('%')[0])"
      ],
      "execution_count": 9,
      "outputs": []
    }
  ]
}